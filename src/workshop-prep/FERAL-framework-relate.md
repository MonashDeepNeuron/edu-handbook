# Relatability

People remember **funny**, **relevant**, or **relatable** things way more than abstract definitions.  
Want someone to understand _anything_ you're teaching?  
**Relate it to them.** Itâ€™s that simple.

### ğŸ’¡ What this means:

- Every topic should connect to **something real** â€“ a meme, a pop culture reference, or a trending app.

- Use **analogies** to explain complex ideas (e.g., _â€œNeural networks are like making pancakes â€“ lots of trial and error before you get it rightâ€_).

- Make it **personal** â€“ ask people about their experiences and how the topic relates to their lives.

### ğŸ” Ask yourself:

âœ… Can you **replace a boring** example with something **cooler**?  
âœ… Is the **explanation fun** without being dumbed down?  
âœ… Are you using **analogies** to make **complex ideas** easier to grasp?

### ğŸ¯ Example:

**Instead of defining recommendation algorithms**, ask:  
_â€œWhatâ€™s the weirdest thing YouTube has ever recommended to you?â€_

Then, explain how AI tracks user behaviour to push content.  
For example, if you watch one Gordon Ramsay video, YouTube thinks you thrive on watching him lose his mind over raw chicken at 2 AM, as if your life depends on it. ğŸ˜­ğŸ˜‚ğŸ—

<figure>
  <img src="./images/relatability3.jpg" alt="Gordon Ramsay relatability example" style="width:100%; border-radius: 10px;">
</figure>

### ğŸ§ª Real-world examples

No exceptions â€“ even the â€œtechnicalâ€ stuff should feel personal.

<figure>
  <img src="./images/relatability1.png" alt="YouTube AI Algorithm Example" style="width:100%; border-radius: 10px;">
  <figcaption><em>Example: Demonstrate the applications of AI via the YouTube algorithm and doomscrolling (AI Workshop)</em></figcaption>
</figure>

<figure>
  <img src="./images/relatability2.png" alt="Clock vs Compass CNN Analogy" style="width:100%; border-radius: 10px;">
  <figcaption><em>Example: Demonstrate the behaviours of CNNs by determining the difference between a clock and a compass (AI Workshop)</em></figcaption>
</figure>
